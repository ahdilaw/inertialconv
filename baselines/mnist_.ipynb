{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiltWCZEXz6e"
   },
   "source": [
    "\n",
    "# Inertia as a Form of Model Compression in Convolutional Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nvzprg3LjNXa"
   },
   "source": [
    "> *In submission for Deep Learning Project, Spring 2025*\n",
    "\n",
    "**Labiba Shahab**\n",
    "\n",
    "**Ahmed Wali**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDVIU3SPZwCS"
   },
   "source": [
    "\n",
    "> *What you usually achieve with a standard convolution, you can accomplish efficiently using a smaller convolution + peripheral inertia mechanism (inertial filter)*\n",
    "~ Group 39\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Gist:\n",
    "\n",
    "Standard dxd convolution layers involve d^2 learnable parameters and d^2 computations per convolution operation. In this project, we propose an inertial convolution mechanism that dynamically decides whether a detailed convolution is necessary. The goal is to reduce both computations and learnable parameters while maintaining performance on vision tasks like MNIST classification.\n",
    "\n",
    "Instead of learning a full dxd kernel, we use a (d-k)x(d-k) core filter to convolve a central patch. The surrounding d^2-(d-k)^2 pixels act as an inertial periphery—evaluating local divergence or “friction.” If the divergence is high, we re-apply the core filter across the full dxd region in another convolution and stack the outputs. If low, we skip detailed computation.\n",
    "\n",
    "In the best case, we perform just d-k computation with d-k learnable parameters.\n",
    "In the worst case, we perform up to d computations, but still only learn d-k parameters, hence effectively pruning the model with estimation compression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-i47fZ7RatOZ"
   },
   "source": [
    "## Background\n",
    "\n",
    "There has been extensive research in reducing neural network complexity:\n",
    "\n",
    "Dynamic convolutions and skip-convolutions conditionally skip expensive operations. This project is inspired from [Dynamic Sparse Convolutions](https://arxiv.org/pdf/2102.04906), [Skip Convolutions](https://openaccess.thecvf.com/content/CVPR2021/papers/Habibian_Skip-Convolutions_for_Efficient_Video_Processing_CVPR_2021_paper.pdf), and [Fractional Skipping](https://arxiv.org/abs/2001.00705)\n",
    "\n",
    "Pruning, quantization, and knowledge distillation reduce parameters, memory, or model depth.\n",
    "\n",
    "Our approach is inspired by these ideas but focuses on parameter reuse and friction-aware skipping, offering a novel trade-off between learning capacity and computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eg1MOaikbd1b"
   },
   "source": [
    "#### Novelty\n",
    "\n",
    "Inspired from computational optimization, our project proposes a similar mechanism to do model compression by estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTrN-SAKcybU"
   },
   "source": [
    "## Baseline Models\n",
    "\n",
    "#### MNIST \n",
    "The baseline LeNet-5 architecture used in our experiments is a direct adaptation of the official PyTorch MNIST example. We preserved all hyperparameters, architecture layers, dropout rates, optimizer, scheduler, and dataset preprocessing to ensure fair and accurate benchmarking against our proposed compressed models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproducibility + Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:49:04.354693Z",
     "iopub.status.busy": "2025-04-14T09:49:04.354461Z",
     "iopub.status.idle": "2025-04-14T09:49:13.613774Z",
     "shell.execute_reply": "2025-04-14T09:49:13.613188Z",
     "shell.execute_reply.started": "2025-04-14T09:49:04.354669Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeds and CuDNN configs for deterministic results on a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:49:13.615644Z",
     "iopub.status.busy": "2025-04-14T09:49:13.615269Z",
     "iopub.status.idle": "2025-04-14T09:49:13.675190Z",
     "shell.execute_reply": "2025-04-14T09:49:13.674442Z",
     "shell.execute_reply.started": "2025-04-14T09:49:13.615626Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:49:13.678190Z",
     "iopub.status.busy": "2025-04-14T09:49:13.677920Z",
     "iopub.status.idle": "2025-04-14T09:49:17.693083Z",
     "shell.execute_reply": "2025-04-14T09:49:17.692347Z",
     "shell.execute_reply.started": "2025-04-14T09:49:13.678164Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 478kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.43MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.5MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('../data', train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:49:17.694403Z",
     "iopub.status.busy": "2025-04-14T09:49:17.694118Z",
     "iopub.status.idle": "2025-04-14T09:49:17.699203Z",
     "shell.execute_reply": "2025-04-14T09:49:17.698449Z",
     "shell.execute_reply.started": "2025-04-14T09:49:17.694384Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    print(f\"Accuracy: {accuracy:.10f}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet 3x3 Model\n",
    "* Adapted from [PyTorch MNIST Example](https://github.com/pytorch/examples/blob/main/mnist/main.py) to use 3x3 kernels, produced as an example in the PyTorch example series on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:49:17.700071Z",
     "iopub.status.busy": "2025-04-14T09:49:17.699900Z",
     "iopub.status.idle": "2025-04-14T09:49:17.717488Z",
     "shell.execute_reply": "2025-04-14T09:49:17.716801Z",
     "shell.execute_reply.started": "2025-04-14T09:49:17.700057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#@adapted from https://github.com/pytorch/examples/blob/main/mnist/main.py \n",
    "class LeNet3x3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet 1x1 Model\n",
    "* Adapted from the above example implementation to use 1x1 kernels instead of the original 3x3 kernels. This model is used to compare the performance of the 1x1 kernel with the original 3x3 kernel in the LeNet architecture, and with the proposed inertial filter model in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:49:17.719760Z",
     "iopub.status.busy": "2025-04-14T09:49:17.719261Z",
     "iopub.status.idle": "2025-04-14T09:49:17.737022Z",
     "shell.execute_reply": "2025-04-14T09:49:17.736263Z",
     "shell.execute_reply.started": "2025-04-14T09:49:17.719731Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LeNet1x1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 1, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(12544, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:49:17.737971Z",
     "iopub.status.busy": "2025-04-14T09:49:17.737739Z",
     "iopub.status.idle": "2025-04-14T09:49:17.752558Z",
     "shell.execute_reply": "2025-04-14T09:49:17.751933Z",
     "shell.execute_reply.started": "2025-04-14T09:49:17.737952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, name):\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "    for epoch in range(1, 15):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    acc = test(model, device, test_loader)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Let's Evaluate MNIST on the Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:57:48.734046Z",
     "iopub.status.busy": "2025-04-14T09:57:48.733317Z",
     "iopub.status.idle": "2025-04-14T10:03:18.108237Z",
     "shell.execute_reply": "2025-04-14T10:03:18.107591Z",
     "shell.execute_reply.started": "2025-04-14T09:57:48.734020Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LeNet 3x3 Results:\n",
      "Accuracy: 0.9917000000\n",
      "\n",
      "LeNet 1x1 Results:\n",
      "Accuracy: 0.9574000000\n"
     ]
    }
   ],
   "source": [
    "model_3x3 = LeNet3x3()\n",
    "acc_3x3 = train_model(model_3x3, \"LeNet 3x3\")\n",
    "model_1x1 = LeNet1x1()\n",
    "acc_1x1 = train_model(model_1x1, \"LeNet 1x1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "\n",
    "This dataset serves as a good starting point due to its simplicity and low variance. We will use this dataset as the initial starting point for our analysis. We will adapt the standard pytorch LeNet-5 implementation with 2 convolutional layers in 3x3 filters. We will then train a similar model with the only alteration made such that the two convolutional layers use 1x1 core filters + 1 pixel periphery, and we would compare the results. If the results are comparable, we would have effectively reduced the number of learnable parameters and potentially the computational bulk due to the smaller kernel size.\n",
    "\n",
    "**What do we expect?**\n",
    "\n",
    "Since the MNIST dataset is a grascale dataset, we anticipate low divergence or friction across patches in images, hence we anticipate improved performance due to the use of inertial filters."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
